{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b997121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be25bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matmul_kernel import matmul_fp16_int4\n",
    "from final_quantization_kernel import quantize_rowwise_int4, dequantize_rowwise_int4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09196d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Benchmarking with 128 tokens\n",
      "============================================================\n",
      "\n",
      "Layer: (2048, 2048) - X[128,2048] @ W[2048,2048]^T\n",
      "  fp16: 0.052 ms\n",
      "  Int4: 0.361 ms\n",
      "  Speedup: 0.14x\n",
      "\n",
      "Layer: (2048, 512) - X[128,2048] @ W[512,2048]^T\n",
      "  fp16: 0.016 ms\n",
      "  Int4: 0.129 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "Layer: (2048, 8192) - X[128,2048] @ W[8192,2048]^T\n",
      "  fp16: 0.179 ms\n",
      "  Int4: 1.296 ms\n",
      "  Speedup: 0.14x\n",
      "\n",
      "Layer: (8192, 2048) - X[128,8192] @ W[2048,8192]^T\n",
      "  fp16: 0.179 ms\n",
      "  Int4: 1.288 ms\n",
      "  Speedup: 0.14x\n",
      "\n",
      "============================================================\n",
      "Benchmarking with 512 tokens\n",
      "============================================================\n",
      "\n",
      "Layer: (2048, 2048) - X[512,2048] @ W[2048,2048]^T\n",
      "  fp16: 0.151 ms\n",
      "  Int4: 1.162 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "Layer: (2048, 512) - X[512,2048] @ W[512,2048]^T\n",
      "  fp16: 0.046 ms\n",
      "  Int4: 0.324 ms\n",
      "  Speedup: 0.14x\n",
      "\n",
      "Layer: (2048, 8192) - X[512,2048] @ W[8192,2048]^T\n",
      "  fp16: 0.612 ms\n",
      "  Int4: 4.547 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "Layer: (8192, 2048) - X[512,8192] @ W[2048,8192]^T\n",
      "  fp16: 0.588 ms\n",
      "  Int4: 4.641 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "============================================================\n",
      "Benchmarking with 2048 tokens\n",
      "============================================================\n",
      "\n",
      "Layer: (2048, 2048) - X[2048,2048] @ W[2048,2048]^T\n",
      "  fp16: 0.591 ms\n",
      "  Int4: 4.534 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "Layer: (2048, 512) - X[2048,2048] @ W[512,2048]^T\n",
      "  fp16: 0.152 ms\n",
      "  Int4: 1.173 ms\n",
      "  Speedup: 0.13x\n",
      "\n",
      "Layer: (2048, 8192) - X[2048,2048] @ W[8192,2048]^T\n",
      "  fp16: 2.436 ms\n",
      "  Int4: 18.018 ms\n",
      "  Speedup: 0.14x\n",
      "\n",
      "Layer: (8192, 2048) - X[2048,8192] @ W[2048,8192]^T\n",
      "  fp16: 2.419 ms\n",
      "  Int4: 18.083 ms\n",
      "  Speedup: 0.13x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "layer_configs = [\n",
    "    (2048, 2048),\n",
    "    (2048, 512), \n",
    "    (2048, 8192),\n",
    "    (8192, 2048),\n",
    "]\n",
    "\n",
    "token_counts = [128, 512, 2048]\n",
    "num_warmup = 10\n",
    "num_iterations = 100\n",
    "\n",
    "results = {}\n",
    "\n",
    "for M in token_counts:\n",
    "    results[M] = {}\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmarking with {M} tokens\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for in_features, out_features in layer_configs:\n",
    "        K, N = in_features, out_features\n",
    "        \n",
    "        print(f\"\\nLayer: ({K}, {N}) - X[{M},{K}] @ W[{N},{K}]^T\")\n",
    "        \n",
    "        X = torch.randn(M, K, device='cuda', dtype=torch.float16)\n",
    "        W_fp16 = torch.randn(N, K, device='cuda', dtype=torch.float16)\n",
    "        \n",
    "        W_int4_packed, scales = quantize_rowwise_int4(W_fp16)\n",
    "        \n",
    "        for _ in range(num_warmup):\n",
    "            _ = torch.matmul(X, W_fp16.t())\n",
    "            _ = matmul_fp16_int4(X, W_int4_packed, scales)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        \n",
    "        start_event.record()\n",
    "        for _ in range(num_iterations):\n",
    "            C_fp16 = torch.matmul(X, W_fp16.t())\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        fp16_time = start_event.elapsed_time(end_event) / num_iterations\n",
    "        \n",
    "        start_event.record()\n",
    "        for _ in range(num_iterations):\n",
    "            C_int4 = matmul_fp16_int4(X, W_int4_packed, scales)\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        int4_time = start_event.elapsed_time(end_event) / num_iterations\n",
    "        \n",
    "        \n",
    "        speedup = fp16_time / int4_time\n",
    "        \n",
    "        results[M][(K, N)] = {\n",
    "            'fp16_time_ms': fp16_time,\n",
    "            'int4_time_ms': int4_time, \n",
    "            'speedup': speedup,\n",
    "        }\n",
    "        \n",
    "        print(f\"  fp16: {fp16_time:.3f} ms\")\n",
    "        print(f\"  Int4: {int4_time:.3f} ms\") \n",
    "        print(f\"  Speedup: {speedup:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
